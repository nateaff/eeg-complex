The complete \texttt{ecomplex} package can be found at 
\texttt{github.com\nateaff\ecomplex}. 

The \texttt{ecomplex.R} contains the main function. On

\begin{verbatim}
#' Compute the epsilon-complexity of a time series.
#'
#' @param x A vector of points. 
#' @param ds Number of times to downsample the input sequence.
#' @param method The interpolation or approximation method. One of
#'                c("bspline", "cspline")
#' @param max_degree The maximum order spline used in the approximation
#'              step
#' @param err_norm The norm type used in computing the approximation error.
#' @param sample_type The downsampling type. Either randomly sampled  
#'                      or downsampled in integer steps.
#'
#' @return A \code{list} with :
#' \tabular{ll}{
#' \code{A}        \tab The epsilon-complexity intercept coefficient \cr
#' \code{B}        \tab The epsilon-complexity slope coefficient \cr
#' \code{fit}      \tab The full linear model generated by fitting log(epsilons) ~ log(S) using \code{lm()}. \cr
#' \code{epsilons} \tab The mean sum of absolute errors at each downsample level. \cr
#' \code{S}        \tab The fraction of samples maintained at each downsample level. \cr
#' \code{method}  \tab The method used or a list of methods if method 
#'                      "all" is used. 
#'}
#'@export
#'@importFrom stats lm coefficients
ecomplex <- function(x, ds = 6, 
                        max_degree = 5,
                        method = c("cspline", "bspline", "lift", "all"), 
                        err_norm = c("mae", "mse", "max"), 
                        sample_type = c("step", "random")) {

  if (!is.null(dim(x))) stop("Data must be a vector of numeric values")
  x <- as.numeric(x)  
  if (anyNA(x))         stop("Data contains NA values")
  if (length(x) < 100)  warning("Complexity estimate may not be stable ", 
                                "for short series")  
  x <- normalize(x)
  method   <- match.arg(method)
  err_norm <- match.arg(err_norm) 
  sample_type <- match.arg(sample_type)

  func <- structure(list(x     = x, 
                         ds    = ds, 
                         deg   = max_degree, 
                         err_norm  = err_norm, 
                         sample_type = sample_type),
                         class = method)

  # Compute error for each downsample level up to 'ds'
  res <- get_epsilons(func)  
  S   <- 1 / (2:(length(res$epsilons) + 1))
  epsilons <- res$epsilons
  method   <- res$methods

  # Catch lm() errors silently and return NA values
  A <- B <- fit <- NA
  try({      
     fit <- lm(log(epsilons) ~ log(S))
     A   <- unname(stats::coef(fit)[1])
     B   <- unname(stats::coef(fit)[2])
  }, silent = TRUE )

  if(is.na(A) || is.na(B)) warning("Coefficients could not be computed.", 
                          " Check data for invalid values.")

  structure(list(A        = A,
                 B        = B,
                 fit      = fit, 
                 epsilons = epsilons, 
                 S        = S,
                 method   = method, 
                 err_norm = err_norm, 
                 sample_type = sample_type), 
                 class    = "ecomplex")
}


#' Compute epsilon errors for a time series.
#'
#' Computes the mean absolute error (MAE) of a time
#'  series for each downsample level using an 
#'  interpolation (or approximation) method of type
#'  basis-spline, cubic spline or lifting sche 
#'
#' @param func A structure with the time series, interpolation method, 
#'              and parameters for the method.
#' @return A \code{list} with :
#' \tabular{ll}{
#' \code{epsilons} \tab The mean sum of absolute errors at each level \cr
#' \code{methods}  \tab The method used or a list of methods if method 
#'                      "all" is used. 
#'}
get_epsilons <- function(func) UseMethod("get_epsilons")

get_epsilons.bspline <- function(func){
  epsilons <- double(func$ds - 1)
  ds <- 2:func$ds
    for (k in ds) {
    epsilons[k - 1] <- bspline_err(func$x, sample_num = k, max_degree = func$deg)
  }
  list(epsilons = epsilons, methods = class(func))
}

get_epsilons.cspline <- function(func){
  epsilons <- double(func$ds - 1)
  ds <- 2:func$ds
    for (k in ds) {
    epsilons[k - 1] <- cspline_err(func$x, sample_num = k, 
                                           max_degree = func$deg, 
                                           err_norm = func$err_norm, 
                                           sample_type = func$sample_type)
  }
  list(epsilons = epsilons, methods = class(func))
}

get_epsilons.lift <- function(func) {
  ds <- min(func$ds, 6)
  epsilons <- unlist(lapply((2:ds), function(y) interp_err(func$x, iwt_mod(y))))
  list(epsilons = epsilons, methods = class(func))
}

# Find best fit among all methods. If the series length
# is longer than 500, this defaults to using just the 
# cubic spline and lift methods.
get_epsilons.all <- function(func){
  methods <- c("cspline", "bspline", "lift")
  if (length(func$x) > 500 ) {
    methods <- c("cspline", "lift")
  }
  eps <- lapply(methods, 
                function(method) get_epsilons({class(func) <- method; func}))
  eps <- lapply(eps, function(eps) eps$epsilons)
  df <- data.frame(do.call(cbind, eps))
  names(df) <- methods
  # get minimum epsilons
  epsilons <- apply(df, 1, min)
  methods_used  <- methods[apply(df, 1, which.min)]
  list(epsilons = epsilons, methods = methods_used)
}
  
\end{verbatim}



The \texttt{palarm.R} file contains the change-point detection function \text{palamr()}, based on the Matlab function by Alexandra Piryatinska and Anatoly Zlotnick. 

\begin{verbatim}
#  Based on the function Palarm2 
#  Anatoly Zlotnik and Alexandra Piryatinska
#  See paper :Automated detection of neonate EEG sleep stages

#' Estimation of change points and mean on each
#' stable interval.
#'
#' @param x Input data.
#' @param delta1 A weighting parameter for phase I.
#' @param delta2 A weighting parmameter for phase II.
#' @param pf False detection probability.
#' @param m  Minimum interval size.
#' @param M  Number of terms in KS series.
#' @param epsilon Minimum relative distance of change point 
#'  from endpoints of local interval.
#'
#' @return 
#'
#' A \code{list} with :
#'
#' \tabular{ll}{
#' \code{kout} \tab Vector of indices of the detected change points,\cr
#' \code{means} \tab Vector of mean values on each stationary segment. \cr
#' }
#'@export
#'@importFrom stats sd
palarm <- function(x, delta1 =1, 
                      delta2 = 0, 
                      pf = 0.1, 
                      m = 5, 
                      M = 1000,
                      epsilon = 0.02){
  xin <- x; x <- (x - mean(x))/sd(x) 
  N <- length(x)   

  thresh <- abs(ksinverse(pf, M))
  p0 <- 1; 
  kin <- double(0); 
  kone <- palarmf(x, kin, p0, delta1, thresh, m, epsilon)
  if(length(kone) == 0){
    kout <- kone;
    out <- mean(xin)*rep(N, 1)

  } else {
    kone <- sort(kone)
    thresh <- abs(ksinverse(pf/10, M))
    kout <- diagn(x, kone, delta2, m, thresh)
  }
  delta3=0.5;
  finalal(x, xin, kout, m, delta3, thresh) 
}


# Returns ksdistribution with parameters (pf,m)
ksdist <- function(pf, m){
  function(y){
    k <- 1:m
    s <- rep(-1, m)^(k+1)
    2*sum(s*exp(-(2*y^2)*(k^2))) -pf  
  }
}


ksinverse <- function(pf, M){
  ks <- ksdist(pf,M)    
  # Adding .005 to 1 to match behavior of 
  # Matlab fzero() function
  res <- pracma::fzero(ks, 1.005)
  res$x
}


#' Calculate statistics for change point and
#'  maximize to detect change point k.
#'
#' @param X Input data.
#' @param delta Detect parameter.
#' @param m Minimum interval size.
#'
#'  
#' @return 
#'
#' A \code{list} with :
#'
#' \tabular{ll}{
#' \code{ystat} \tab The test stastistic,\cr
#' \code{k} \tab The estimated change point \cr
#' }
ystat <- function(X, delta, m){
  N <- length(X)
  Y <- 1:(N-1)
  stopifnot( N > 1 )
  stat <- rep(1, N)
  M1 <- cumsum(X[1:(N-1)])/Y
  M2 <- rev(cumsum(rev(X[2:N]))/Y)
  stat <- abs((((1- (Y/N))*(Y/N))^delta)*(M1-M2))
  
  k <- which.max(round(stat, 3))
  list(stat = stat, k = k)
}


# 2004 by Anatoly Zlotnik and Alexandra Piryatinska

#' Recursive algorithm for detection of change points by successive interval
#' bisection.
#'
#' 
#' @param  X      Local data.
#' @param kin     Vector containing estimated global change points.
#' @param P       Global index of first point of local data.
#' @param delta   Detect parameter.
#' @param thresh  Minimum statistic for change point characterization.
#' @param m       Minimum interval size.
#' @param epsilon Minimum relative distance of change point from endpoints.
#'
#'  @return kout    Updated vector of estimated global change points.
palarmf <- function( X, 
                    kin = double(0), 
                    P = 1, 
                    delta = 1, 
                    thresh = 1.224, 
                    m = 5, 
                    epsilon = 0.02 ){
  res <- ystat(X, delta, m)
  k <- res$k 
  stat <- res$stat
  N <- length(X) 
  sigma <- sd(c(X[1:k] - mean(X[1:k]) , X[(k+1):N]- mean(X[(k+1):N])))/sqrt(N)
  
  level <- thresh*sigma
  d <- max(round(epsilon*N), 1)
  if(stat[k] < level){
    kout <- kin
  } else {
    X1 <- X[1:( k-d )] 
    P1 <- P
    X2 <- X[(k + d ):N]
    P2 <- P + k + d - 1;
    
    if( length(X1) <= m ){
       Ktemp1 <- kin
     } else if (length(X1) > m) {
       Ktemp1 <- palarmf( X1, kin, P1, delta, thresh, m, epsilon)
    }
    if( length(X2) <= m ){ 
      Ktemp2 <- Ktemp1
    } else if( length(X2) > m ) {
       Ktemp2 <- palarmf( X2, Ktemp1, P2, delta, thresh, m, epsilon )
    }
    if( length(X1) > m && length(X2) > m ) {
      kout <- c( Ktemp2, P + k - 1 )
    }
    else kout <- Ktemp2
  } 
  return(kout)
}

#' Checks estimated global change points for errors 
#'  and performs update.
#'
#' @param x Input data.
#' @param kin A vector containing estimated global change points.
#' @param delta Detect parameter.
#' @param m Minimum interval size.
#' @param thresh Minimum statistic for change point characterization.
#' (
#' @return kout Estimated global change points.
diagn <- function(x, kin, delta, m, thresh){
  N <- length(x); 
  Z <- length(kin); 
  kout <- double(0)
  # Some change points found
  
  if(length(kin) > 1) {
    b <- floor((kin[2] + kin[1])/2); a <- 0;
    kout <- check_pt(x[1:b], a, delta, m, thresh, kout)
    if(length(kin) > 2){
      for(i in 2:(length(kin)-1)){
        a <- floor((kin[i] + kin[i - 1])/2) + 1
        b <- floor((kin[i + 1] + kin[i])/2)
        kout <- check_pt(x[a:b], a, delta, m, thresh, kout)
      } # end for
    }
    # final change point 
    a <- round((kin[Z]+ kin[Z-1])/2)
    b = N;
    kout <- check_pt(x[a:N], a, delta, m, thresh, kout)
  } else {
    stats <- ystat(x, delta, m)
    if(stats$stat[stats$k] > (thresh*(sd(x)/sqrt(N))) ) {
      kout <- c(kout, stats$k)
    }
  }
  kout 
}


check_pt <- function(x, start, delta, m, thresh, kout){
  stats <- ystat(x, delta, m) 
  sigma <- sd(x)/sqrt(length(x)-1) 
  level <- thresh*sigma

  adjust <- 0
  if(start > 0) adjust <- 1
  pos <- start + stats$k - adjust

  if(stats$stat[stats$k] > level){
      kout <- c(kout, pos)
  }
  kout
}



#' Calculate final change point estimates and mean of each interval
#'  Based on Matlab function of Anatoly Zlotnik and Alexandra Piryatinska
#'    
#' @param X       Input data.
#' @param xin     The original time-series.
#' @param kin     A vector containing estimated global change points
#' @param m       Minimum interval size.
#' @param delta   Detect parameter.
#' @param thresh  Threshold for detecting change-point.
#'
#' A \code{list} with :
#'
#' \tabular{ll}{
#' \code{meanK} \tab the mean values of the intervals,\cr
#' \code{kout} \tab the final estimated change points.\cr
#' }
finalal <- function(X, xin, kin, m, delta, thresh){

N <- length(X); 
Z <- length(kin);

kout <- double(0) 

if(length(kin)>1) {
    b <- floor((kin[2] + kin[1])/2);
    X1 <- X[1:b];
    stats <- ystat(X1,delta,m);
    
    if(stats$k > 1) {
        me <- mean(xin[1:(stats$k-1)])
        meanK <- me*rep(1, (stats$k - 1))
        } else {
        meanK <- double(0)
    }
      kout <- c(kout, stats$k)
    # 
    if(length(kin) > 2 ){
      for(i in 2:(length(kin)-1)){
          a <- floor((kin[i] + kin[i-1] )/2) + 1
          b <- floor((kin[i+1] + kin[i])/2)
          stats <- ystat(X[a:b], delta,m)
          kout <- c(kout, a + stats$k - 1 )
          M1 <- mean(xin[(kout[i-1]+1):(kout[i]-1)])
          M2 <- M1*(rep(1, kout[i]-kout[i-1] ))
          meanK <- c(meanK, M2)
      }
    }
    a <- round((kin[Z] + kin[Z-1])/2)
    X1 <- X[a:N]
    stats <- ystat(X1, delta, m);
    kout <- c(kout, a + stats$k - 1);
    M1 <- mean(xin[ (1 + kout[Z-1]): (kout[Z]-1)] )
    M2 <- M1*(rep(1 ,kout[Z]-kout[Z-1]))
    meanK <- c(meanK, M2)
    M3 <- mean(xin[(kout[Z] + 1):N])
    meanK <- c(meanK, M3*rep(1 , N - kout[Z]+1))
  } else {
     stats  <- ystat(X, delta, m); 
     kout <-  c(kout, stats$k)
     meanK <- c(rep(1, stats$k) * mean(xin[1:stats$k]), 
                rep(1, N - stats$k) * mean(xin[ stats$k:N] )) 
  }
  structure(list(kout = kout, means = meanK), class = "palarm")
}


\end{verbatim}

The \texttt{utils.R} file contains miscellaneous functions most 
of which are used internally by other functions. The functions were
exported to ease production and testing.

\begin{verbatim}
 #' Normalize sequence values to (0,1).
#'
#' Computes (x - min x)/(max x - min x).
#'
#' @param  x The sequence to normalize.
#' @return  The normalized sequence.
#' @export
normalize <- function(x){
    if(!max(x) == min(x)){
      (x - min(x))/(max(x) - min(x)) 
    } else {
      rep(0, length(x))
    }
  }


#' Create list of all possible index patterns 
#'  for a given downsampling amount.
#' 
#' Creates a list of indices that correspond to 
#'  possible downsampling of a vector of length n
#'  at the given downsample rate.
#'
#' @param  n Length of list.
#' @param  ds Downsample rate.
#'
#' @return  List of indices 
#' @export
downsample_perm <- function(n, ds){
  x   <- 1:n
  ind  <- vector("list", ds)    
  for (k in 1:ds){
    ind[[k]] <- x[(x - (k))%% ds == 0] 
  }
  ind
}

#' Create indices to randomly downsample a sequence.
#' 
#' Creates a list of indices that sample a fractional
#'  of the total values. The fraction sampled is
#'  1/2:ds, the same fraction sampled in downsample_perm.
#'
#' @param  n Length of list.
#' @param  ds Downsample rate.
#'
#' @return  List of indices 
#' @export
random_sample <- function(n, ds){
  x <- 1:n
  sample_num <- floor(1/ds * n)
  ind <- vector("list", ds)
  for (k in 1:ds){
    ind[[k]] <- sort(sample(x, sample_num, replace = FALSE))
  }
  ind
}

#----------------------------------------------------------
# Added for testing affect of error types. 
# In summary, mae and mse performed similarly.
#----------------------------------------------------------

# mean computed in error function
mae <- function(x, y){
  sum(abs(x - y))
}

mse <- function(x, y){
  sum((x - y)^2)
}

maxerr <- function(x, y){
  max(abs(x - y))
}

 
\end{verbatim}
