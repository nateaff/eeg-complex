% \documentclass[thesis]{subfiles}

% \begin{document}
% main.tex, to be used with thesis.tex
% This contains the main work of your thesis.

% \include{}

\chapter{Introduction}

% Time-series arising 
% in biomedical contexts are often complex and have
% underlying mechanisms that are not well understood. 
% Applications of classification and clustering arise
% naturally in this context; 
% For example, time series collected 
% from the electrical potential generated by the heart -- 
% electrocardiograms (ECG) -- or by the collective 
% firing of synapses as captured by an 
% electroencephalogram (EEG), 
% or generated by direct measurements of human motion,
% are commonly used to monitor and classify the health 
% of patients. 
% time series. 
% Although in practice the line between diagnosiing 
% and modeling a biological process may not be 
% precise, the distinction is useful when considering
% what feature or model of a time series are of 
% interest, as it mirrors the trade off that 
% is often made between interpretation and 
% accuracy in modeling and predicting phenomena.
%  The purely diagnostic setting corresponds
% closely to the algorithmic task of classifying 
% signals
% ==================================
%  old 
% ==================================
% A common practice is to model these time series using
% parametric models for which assumptions made about the
% nature of the process generating the data. However, 
% biophysical time series are often complex, non-stationary
% or have non-linear characteristics.
% parameters for the model are often either iteratively 
% tuned or are restricted to a specific range based
% on domain knowledge. 
Many natural phenomena produce time series with complex statistical properties and with
underlying dynamics that are not well understood. 
For example, electroencephalogram(EEG) record
the electrical potential generated by the synchronized
firing of neurons. EEG signals are non-stationary and exhibit varying functional characteristics over short time frames. The $\varepsilon-$complexity coefficients as defined by Darkhovsky and Piryatinska provide a model 
free way of characterizing a function or time series 
\cite{darkhovsky2013}.
In particular, the complexity of a continuous function
is quantified by estimating the amount of information needed to approximate the function within some error. 

The $\varepsilon-$complexity coefficients are computed by iteratively approximating a function using successively fewer samples of the function. The first implementation of the algorithm for estimating the $\varepsilon-$complexity coefficients
used piecewise polynomials. We implement the algorithm with three related approximation methods -- basis splines, cubic splines, and an interpolating subdivision 
method termed the lifting scheme. For a suite of stochastic processes, we compare the accuracy of the approximation methods and the performance of each method in a classification task. An initial hypothesis was that an enlarged set of approximation
methods would improve the 
behavior of the $\varepsilon-$complexity coefficients.
We find that both the lifting scheme 
and cubic splines produced slightly higher average approximation errors than basis splines but the two methods performed better than basis splines in the classification task.

Darkhovsky and Piryatinska have proved that for a H\"older class of functions the theoretical $\varepsilon$-complexity coefficients capture a linear relationship between the log of the approximation error and the log of the fraction of points used in the approximation. They have conjectured
that a generating mechanism leads to constant mean 
complexity coefficients.
 We use the several simulations with known H\"older 
 exponents to first check the performance of our implementation 
 and then to test if the conjecture holds. The H\"older exponent
 of a function is closely related to the fractal dimension 
 of the graph of a function. For the same set of simulations 
 we compare the complexity 
 coefficients to an estimator of fractal dimension and 
 find the slope coefficient $B$ closely related to the 
fractal dimension estimator

In the final chapter, we use the complexity coefficients
along with a set of spectral features to predict seizures in epileptic mice. The characteristics of the EEG signal can change rapidly over a short time period. Common classification methods use features averaged over arbitrary windows of time. 
We test whether segmenting time series based on changes in the epsilon complexity coefficients improves the prediction of seizures. This dynamic segmentation method is compared to uniform segmentation of trials. 
The best classification is achieved on a regular partition of the time series, although segmentation on change points of the two complexity coefficients performed about as well. The data contained only a small number of trials and a comparison of segmentation methods on a broader range of data would be needed to reach any conclusions about whether these results 
generalize to other contexts.

Finally, we have created an \texttt{R} language package, 
\texttt{ecomplex}, that implements 
the $\varepsilon$-complexity algorithm. Several 
default settings are based on the simulation 
experiments described in Chapter 3. Methods used 
for generating simulations, computing EEG features, 
and the classification algorithm used in Chapter 5 
have been also been included in \texttt{R} 
packages to encourage additional work on related 
topics or replication of the results found here.

% \section{The lifting scheme}
% % In theory, the minimum 
% % estimation error at each step given any family 
% % of functions used to interpolate (or approximate)
% % the original function.
% In theory, the approximation error found at each 
% stage of the algorithm should be all possible 
% families of approximating functions.
%  In practice, 
% some well-defined family of functions is used.
% We implement the $\epsilon-$complexity 
% algorithm using two related 
% methods: basis splines (B-splines)and
%  wavelet splines. The wavelet splines 
%  are implemented using a computationally 
% efficient method called a lifting scheme\cite{sweldens}. 
% One motivation for 
% extending the family of approximating functions is 
% to minimize the approximation error at each 
% stage of the algorithm. Wavelet splines, though, are 
% essentially an iterated version of basis spline
% interpolation. That is, a single iteration of the 
% wavelet spline interpolation is equivalent to 
% interpolation using B-splines.
% The resulting reconstruction error does not differ
% significantly from the B-spline implementation. 
% However, the listing scheme 
% provides an time and space efficient method 
% for computing the interpolation. 

% % Since the spacing 
% % of the points used for interpolation are known 
% % at each stage of the algorithm a discrete time 
% %  filter can be computed before hand,
% % allowing for an efficient computation of the 
% % interpolated points.
% % (Specific claims f a faster implementation to 
% % be detailed later).


% % (transition)

% \section{Classification of EEG}

% % The $\epsilon$-complexity algorithm relies on
% % repeated reconstruction of the original data at  
% % coarser levels, or repeated downsampling of 
% % the data. This makes it best suited for 
% % densely sampled data. 

 
% % mice with a genetic disorder that makes them 
% % prone to epilepsy. 

% % (Explanation)
% The EEG signal measures the changes 
% in the brain's electrical field potential. 
% EEG signals are used in a range 
% of biomedical contexts, from diagnosing
% diseases of the brain to medical
% and commercial brain-computer applications.
% Traditional
% EEG analysis has focused on the spectral
% characteristics of the EEG signal. 
% A typical analysis characterizes a brain 
% state by the relative power within a given 
% frequency band. For example, low frequency 
% delta waves (0.5-4 Hz) and mid-frequency 
% alpha waves (8-12 Hz) have been associated 
% with distinct sleep stages.
%  However, EEG signals exhibit a range of 
%  complex characteristics. For example, 
%  EEG are non-homogeneous, non-stationary and have transient 
%  waveforms. \cite{pirya2009}
%  These
% characteristics make it difficult to analyze
% using standard parametric time series models.\cite{subha} 
% In addition to spectral characteristics 
% a range of features drawn from the study dynamic
% and non-linear systems -- fractional dimension, 
% correlation dimension, and higher order spectra
% have been used to study or classify EEG 
% signals.\cite{subha} 

% In this thesis we use a combination of these  
% features to study EEG signals of mice with 
% a genetic mutation that causes epilepsy. 
% We use the $\epsilon-$complexity algorithm 
% combined with spectral features and variance
% features to segment and classify the EEG 
% signals. In particular, we (attempt) to 
% predict the reaction of the mice to a stimulus
% intended to induce an epileptic reaction. 
% We use a change point algorithm to segment 
% data and then extract features from related 
% segments. The features drawn from this segmented
% data are then used to predict the post stimulus
% brain state of the mice.

% \section{The \texttt{ecomplex R} package}

% We have written an \texttt{R} package that includes 
% the $\epsilon-$complexity algorithm.  
% The package also the change point detection 
% algorithm used in our EEG analysis and  
% described in \cite{pirya2009}.[update] 
% A separate package includes code that 
% allows for the replication of our 
% analysis of synthetic time series and 
% mouse EEG data.


% We begin by outlining the motivation for the 
% $\epsilon-$complexity algorithm and we develop
% the mathematical theory of the procedure. We 
% review several features
% that aim to quantify 'complexity', 
% and describe their relation to the $\epsilon$-complexity
% feature. The mathematical background of 
% lifting scheme interpolation and it's relation to 
% wavelets is described along with the details 
% of the algorithm's implementation in the 
% \texttt{ecomplex} package. The new implementation 
% is tested on a set of synthetic data. Finally, 
% an analysis and classification of the 
%  the mutant epileptic mouse EEG 
% carried out using a change point algorithm and 
% a set of additional features including 
% measures of the variance and spectral content
% of the signal.


